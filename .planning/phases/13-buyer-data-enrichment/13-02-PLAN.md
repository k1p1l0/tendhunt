---
phase: 13-buyer-data-enrichment
plan: 02
type: execute
wave: 2
depends_on: ["13-01"]
files_modified:
  - workers/enrichment/package.json
  - workers/enrichment/wrangler.toml
  - workers/enrichment/tsconfig.json
  - workers/enrichment/src/index.ts
  - workers/enrichment/src/types.ts
  - workers/enrichment/src/db/client.ts
  - workers/enrichment/src/db/enrichment-jobs.ts
  - workers/enrichment/src/db/buyers.ts
  - workers/enrichment/src/db/data-sources.ts
  - workers/enrichment/src/enrichment-engine.ts
  - workers/enrichment/src/stages/01-classify.ts
  - workers/enrichment/src/api-clients/rate-limiter.ts
autonomous: true

must_haves:
  truths:
    - "Enrichment Worker project scaffolded at workers/enrichment/ with wrangler.toml, package.json, tsconfig"
    - "Worker can connect to MongoDB Atlas using native driver (same pattern as data-sync Worker)"
    - "Stage 1 (classify) fuzzy-matches buyer names against DataSource entries using Fuse.js"
    - "Classification results written to Buyer.orgType, Buyer.dataSourceId fields"
    - "EnrichmentJob tracks Stage 1 progress with cursor-based resumability"
  artifacts:
    - path: "workers/enrichment/wrangler.toml"
      provides: "Worker config with daily cron and R2 bucket binding"
      contains: "tendhunt-enrichment"
    - path: "workers/enrichment/src/index.ts"
      provides: "Worker entry point with scheduled handler"
      exports: ["default"]
    - path: "workers/enrichment/src/enrichment-engine.ts"
      provides: "Stage-based pipeline orchestrator with cursor resumability"
      min_lines: 50
    - path: "workers/enrichment/src/stages/01-classify.ts"
      provides: "Fuse.js fuzzy matching of buyers to DataSource entries"
      min_lines: 40
    - path: "workers/enrichment/src/db/client.ts"
      provides: "MongoDB native driver connection (ported from data-sync)"
      min_lines: 20
    - path: "workers/enrichment/src/api-clients/rate-limiter.ts"
      provides: "Per-domain rate limiter with configurable delays"
      min_lines: 30
  key_links:
    - from: "workers/enrichment/src/index.ts"
      to: "workers/enrichment/src/enrichment-engine.ts"
      via: "processEnrichmentPipeline call"
      pattern: "processEnrichmentPipeline"
    - from: "workers/enrichment/src/enrichment-engine.ts"
      to: "workers/enrichment/src/stages/01-classify.ts"
      via: "stage function import"
      pattern: "classify"
    - from: "workers/enrichment/src/stages/01-classify.ts"
      to: "fuse.js"
      via: "import Fuse"
      pattern: "Fuse"
---

<objective>
Scaffold the enrichment Cloudflare Worker at workers/enrichment/ and implement Stage 1 (buyer classification via Fuse.js fuzzy name matching against the DataSource collection).

Purpose: Create the Worker infrastructure and the first enrichment stage that classifies all ~2,384 buyers by organization type, which determines the enrichment strategy for subsequent stages (ModernGov API vs website scraping vs skip).

Output: A deployable Cloudflare Worker with Stage 1 classification, MongoDB connection, enrichment engine, and rate limiter.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/13-buyer-data-enrichment/13-RESEARCH.md
@.planning/phases/13-buyer-data-enrichment/13-01-SUMMARY.md

# Existing Worker patterns to replicate
@workers/data-sync/src/index.ts
@workers/data-sync/src/sync-engine.ts
@workers/data-sync/src/db/buyers.ts
@workers/data-sync/wrangler.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Scaffold enrichment Worker with MongoDB client, types, and rate limiter</name>
  <files>
workers/enrichment/package.json
workers/enrichment/wrangler.toml
workers/enrichment/tsconfig.json
workers/enrichment/src/types.ts
workers/enrichment/src/db/client.ts
workers/enrichment/src/db/enrichment-jobs.ts
workers/enrichment/src/db/buyers.ts
workers/enrichment/src/db/data-sources.ts
workers/enrichment/src/api-clients/rate-limiter.ts
  </files>
  <action>
Create the enrichment Worker project at workers/enrichment/ following the exact same patterns as workers/data-sync/.

**workers/enrichment/package.json:**
```json
{
  "name": "tendhunt-enrichment",
  "private": true,
  "scripts": {
    "dev": "wrangler dev",
    "deploy": "wrangler deploy"
  },
  "devDependencies": {
    "@cloudflare/workers-types": "^4.20250312.0",
    "@types/node": "^22.0.0",
    "typescript": "^5.8.0",
    "wrangler": "^4.12.0"
  },
  "dependencies": {
    "mongodb": "^6.16.0",
    "fast-xml-parser": "^5.2.0",
    "fuse.js": "^7.1.0",
    "@anthropic-ai/sdk": "^0.39.0",
    "p-limit": "^6.2.0"
  }
}
```

Run `npm install` in workers/enrichment/.

**workers/enrichment/wrangler.toml:**
```toml
name = "tendhunt-enrichment"
main = "src/index.ts"
compatibility_date = "2025-03-20"
compatibility_flags = ["nodejs_compat_v2"]

[triggers]
crons = ["0 2 * * *"]  # Daily at 2 AM UTC

[[r2_buckets]]
binding = "DOCS"
bucket_name = "tendhunt-enrichment-docs"

# Secrets: MONGODB_URI, ANTHROPIC_API_KEY
# Set via: wrangler secret put MONGODB_URI
#          wrangler secret put ANTHROPIC_API_KEY
```

**workers/enrichment/tsconfig.json:**
Copy from workers/data-sync/tsconfig.json, adjust paths.

**workers/enrichment/src/types.ts:**
Define:
- `Env` interface: { MONGODB_URI: string; ANTHROPIC_API_KEY: string; DOCS: R2Bucket }
- `EnrichmentStage` type: "classify" | "governance_urls" | "moderngov" | "scrape" | "personnel" | "score"
- `EnrichmentJobDoc` interface matching the EnrichmentJob Mongoose schema
- `DataSourceDoc` interface matching the DataSource schema
- `BuyerDoc` interface with buyer fields + enrichment fields
- `KeyPersonnelDoc` interface matching KeyPersonnel schema
- `BoardDocumentDoc` interface matching BoardDocument schema

**workers/enrichment/src/db/client.ts:**
Port from workers/data-sync/src/db/client.ts. Same MongoDB native driver pattern with getDb(uri) and closeDb(). Add MongoClientOptions type cast for @cloudflare/workers-types compatibility (same fix as data-sync: `as unknown as MongoClientOptions`).

**workers/enrichment/src/db/enrichment-jobs.ts:**
- getOrCreateJob(db, stage): Get existing job or create new one for the stage
- updateJobProgress(db, jobId, updates): Update cursor, totalProcessed, totalErrors
- markJobComplete(db, jobId): Set status to "complete"
- markJobError(db, jobId, errorMsg): Set status to "error", push to errorLog

**workers/enrichment/src/db/buyers.ts:**
- getBuyerBatch(db, cursor, batchSize): Fetch batch of buyers after cursor, sorted by _id
- updateBuyerEnrichment(db, buyerId, fields): Update buyer with enrichment fields
- bulkUpdateBuyerEnrichment(db, updates): Bulk update multiple buyers with $set

**workers/enrichment/src/db/data-sources.ts:**
- getAllDataSources(db): Fetch all DataSource documents (cached in memory for fuzzy matching)
- getDataSourceByName(db, name): Find single DataSource by exact name

**workers/enrichment/src/api-clients/rate-limiter.ts:**
Port and extend from data-sync rate-limiter. Add per-domain rate limiting:
```typescript
const DOMAIN_DELAYS: Record<string, number> = {
  "moderngov": 2000,     // 1 req/2s per council site
  "nhs.uk": 2000,
  "gov.uk": 1000,
  "default": 3000,
};
```
Track last request time per domain. Export fetchWithDomainDelay(url) that waits the appropriate delay before fetch, plus existing exponential backoff on 429/503.
  </action>
  <verify>
```bash
cd workers/enrichment && npm install && npx tsc --noEmit
```
Verify all files compile and dependencies install correctly.
  </verify>
  <done>
- workers/enrichment/ project scaffolded with package.json, wrangler.toml, tsconfig.json
- MongoDB native driver client ported from data-sync Worker
- EnrichmentJob CRUD operations for tracking pipeline progress
- Buyer batch fetch and enrichment update operations
- DataSource fetch operations for classification
- Per-domain rate limiter with configurable delays per domain
- All TypeScript compiles without errors
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement enrichment engine and Stage 1 classification with Fuse.js</name>
  <files>
workers/enrichment/src/enrichment-engine.ts
workers/enrichment/src/stages/01-classify.ts
workers/enrichment/src/index.ts
  </files>
  <action>
**workers/enrichment/src/enrichment-engine.ts:**
Create the stage-based pipeline orchestrator following the sync-engine.ts pattern but with stage progression instead of source-based sync.

```typescript
export async function processEnrichmentPipeline(
  db: Db,
  env: Env,
  maxItemsPerRun: number = 500
): Promise<{ stage: string; processed: number; errors: number; done: boolean }>
```

Logic:
1. Determine current stage: Check EnrichmentJob collection for the first incomplete stage in order: classify -> governance_urls -> moderngov -> scrape -> personnel -> score
2. Get or create job for that stage
3. If job status is "complete", move to next stage
4. Call the appropriate stage function, passing db, job, and maxItemsPerRun
5. The stage function processes buyers in batches, saving cursor after each batch
6. Return { stage, processed, errors, done }

Each stage function must have the signature:
```typescript
type StageFn = (db: Db, env: Env, job: EnrichmentJobDoc, maxItems: number) => Promise<{ processed: number; errors: number; done: boolean }>;
```

Generic batch processor (shared utility):
```typescript
async function processInBatches(
  db: Db,
  job: EnrichmentJobDoc,
  batchFn: (batch: BuyerDoc[]) => Promise<number>,
  maxItems: number,
  filter?: Record<string, unknown>
): Promise<{ processed: number; errors: number; done: boolean }>
```
- Fetches buyer batches after cursor
- Calls batchFn for each batch
- Saves cursor after each batch
- Returns when maxItems reached or no more buyers

**workers/enrichment/src/stages/01-classify.ts:**
Implement Stage 1: fuzzy name matching of buyers against DataSource collection.

```typescript
export async function classifyBuyers(
  db: Db, env: Env, job: EnrichmentJobDoc, maxItems: number
): Promise<{ processed: number; errors: number; done: boolean }>
```

Logic:
1. Load ALL DataSource documents into memory (2,368 entries -- fits easily)
2. Create Fuse.js instance with options:
   - keys: ["name"]
   - threshold: 0.3 (strict but allowing abbreviation differences)
   - ignoreLocation: true (don't penalize position in string)
   - includeScore: true
   - minMatchCharLength: 3
3. Process buyers in batches of 100 (from cursor):
   - For each buyer, normalize name: strip "The", "Borough", "Council", "of", "City", "Royal", "NHS Trust", "Foundation Trust", lowercase, trim excess whitespace
   - Run fuse.search(normalizedName)
   - If match found with score < 0.3:
     - Update buyer with: orgType, dataSourceId, democracyPortalUrl, democracyPlatform, boardPapersUrl (all from matched DataSource)
     - Track as matched
   - If no match:
     - Log unmatched buyer name for review
     - Still mark as processed
   - Save cursor after each batch

4. Use bulkUpdateBuyerEnrichment for efficient batch writes

**workers/enrichment/src/index.ts:**
Worker entry point with scheduled handler:

```typescript
export default {
  async scheduled(controller, env, ctx) {
    const db = await getDb(env.MONGODB_URI);
    try {
      console.log("--- Starting enrichment pipeline ---");
      const result = await processEnrichmentPipeline(db, env, 500);
      console.log(`Stage ${result.stage}: processed=${result.processed}, errors=${result.errors}, done=${result.done}`);
    } catch (err) {
      console.error("Enrichment failed:", err);
      throw err;
    } finally {
      await closeDb();
    }
  }
} satisfies ExportedHandler<Env>;
```

For now, only Stage 1 is wired. The enrichment engine should gracefully handle missing stage functions by logging a message and skipping (stages 2-6 will be added in subsequent plans).
  </action>
  <verify>
```bash
cd workers/enrichment && npx tsc --noEmit
```

To verify the Fuse.js matching works correctly, create a simple test by running:
```bash
cd workers/enrichment && npx wrangler dev --test-scheduled
```
Or verify by deploying and triggering manually.
  </verify>
  <done>
- Enrichment engine processes stages sequentially with cursor-based resumability
- Stage 1 classifies buyers via Fuse.js fuzzy matching against DataSource collection
- Buyer orgType, dataSourceId, and governance URLs populated from matched DataSource
- Unmatched buyers are logged for manual review
- Worker entry point wired with scheduled handler
- Progress tracked in EnrichmentJob collection (cursor, totalProcessed, totalErrors)
- Engine gracefully handles missing stage functions for stages 2-6
  </done>
</task>

</tasks>

<verification>
1. Worker compiles: `cd workers/enrichment && npx tsc --noEmit`
2. All source files exist in correct directory structure
3. wrangler.toml has daily cron trigger and R2 bucket binding
4. Enrichment engine processes Stage 1 with batch processing and cursor resume
5. Fuse.js configured with threshold 0.3 and ignoreLocation for robust matching
6. MongoDB operations follow data-sync patterns (native driver, bulk operations)
7. Rate limiter supports per-domain delays
</verification>

<success_criteria>
- Enrichment Worker scaffolded at workers/enrichment/ with all dependencies
- Stage 1 (classify) fuzzy-matches buyers against DataSource and updates orgType + governance URLs
- EnrichmentJob tracks progress for crash-safe resume across Worker invocations
- Worker entry point runs pipeline on daily cron schedule
- TypeScript compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/13-buyer-data-enrichment/13-02-SUMMARY.md` documenting:
- Worker scaffold details (files, dependencies, config)
- Stage 1 classification logic and Fuse.js configuration
- Enrichment engine architecture (stage progression, cursor resume)
- Files created
</output>
